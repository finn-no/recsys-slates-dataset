{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dataset_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset_torch\n",
    "\n",
    "> Module to load the slates dataset into a Pytorch Dataset and Dataloaders with default train/valid test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import recsys_slates_dataset.datahelper as datahelper\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level='INFO')\n",
    "\n",
    "class SequentialDataset(Dataset):\n",
    "    '''\n",
    "     Note: displayType has been uncommented for future easy implementation.\n",
    "    '''\n",
    "    def __init__(self, data, sample_uniform_slate=False):\n",
    "\n",
    "        self.data = data\n",
    "        self.num_items = self.data['slate'].max()+1\n",
    "        self.sample_uniform_slate = sample_uniform_slate\n",
    "        logging.info(\n",
    "            \"Loading dataset with slate size={} and uniform candidate sampling={}\"\n",
    "            .format(self.data['slate'].size(), self.sample_uniform_slate))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = {key: val[idx] for key, val in self.data.items()}\n",
    "\n",
    "        if self.sample_uniform_slate:\n",
    "            # Sample actions uniformly:\n",
    "            action = torch.randint_like(batch['slate'], low=3, high=self.num_items)\n",
    "            \n",
    "            # Add noclick action at pos0 \n",
    "            # and the actual click action at pos 1 (unless noclick):\n",
    "            action[:,0] = 1\n",
    "            clicked = batch['click']!=1\n",
    "            action[:,1][clicked] = batch['click'][clicked]\n",
    "            batch['slate'] = action\n",
    "            # Set click idx to 0 if noclick, and 1 otherwise:\n",
    "            batch['click_idx'] = clicked.long()\n",
    "            \n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dataloaders(data_dir= \"dat\",\n",
    "                     batch_size=1024,\n",
    "                     num_workers= 0,\n",
    "                     sample_uniform_slate=False,\n",
    "                     valid_pct= 0.05,\n",
    "                     test_pct= 0.05,\n",
    "                     t_testsplit= 5):\n",
    "    \"\"\"\n",
    "    Loads pytorch dataloaders to be used in training. If used with standard settings, the train/val/test split is equivalent to Eide et. al. 2021 \n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Download data if not in data folder..\")\n",
    "    datahelper.download_data_files(data_dir=data_dir)\n",
    "\n",
    "    logging.info('Load data..')\n",
    "    with np.load(\"{}/data.npz\".format(data_dir)) as data_np:\n",
    "        data = {key: torch.tensor(val) for key, val in data_np.items()}\n",
    "    dataset = SequentialDataset(data, sample_uniform_slate)\n",
    "    \n",
    "    with open('{}/ind2val.json'.format(data_dir), 'rb') as handle:\n",
    "        # Use string2int object_hook found here: https://stackoverflow.com/a/54112705\n",
    "        ind2val = json.load(\n",
    "            handle, \n",
    "            object_hook=lambda d: {\n",
    "                int(k) if k.lstrip('-').isdigit() else k: v \n",
    "                for k, v in d.items()\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Split dataset into train, validation and test:\n",
    "    num_validusers = int(len(dataset) * valid_pct)\n",
    "    num_testusers = int(len(dataset) * test_pct)\n",
    "    torch.manual_seed(0)\n",
    "    num_users = len(dataset)\n",
    "    perm_user = torch.randperm(num_users)\n",
    "    valid_user_idx = perm_user[:num_validusers]\n",
    "    test_user_idx  = perm_user[num_validusers:(num_validusers+num_testusers)]\n",
    "    train_user_idx = perm_user[(num_validusers+num_testusers):]\n",
    "    # Mask type: 1: train, 2: valid, 3: test\n",
    "    dataset.data['mask_type'] = torch.ones_like(dataset.data['click'])\n",
    "    dataset.data['mask_type'][valid_user_idx, t_testsplit:] = 2\n",
    "    dataset.data['mask_type'][test_user_idx, t_testsplit:] = 3\n",
    "\n",
    "    subsets = {\n",
    "        'train': dataset, \n",
    "        'valid': torch.utils.data.Subset(dataset, valid_user_idx),\n",
    "        'test': torch.utils.data.Subset(dataset, test_user_idx)\n",
    "        }\n",
    "\n",
    "    # Build dataloaders for each data subset:\n",
    "    dataloaders = {\n",
    "        phase: DataLoader(ds, batch_size=batch_size, shuffle=(phase==\"train\"), num_workers=num_workers)\n",
    "        for phase, ds in subsets.items()\n",
    "    }\n",
    "    for key, dl in dataloaders.items():\n",
    "        logging.info(\n",
    "            \"In {}: num_users: {}, num_batches: {}\".format(key, len(dl.dataset), len(dl))\n",
    "        )\n",
    "    \n",
    "    # Load item attributes:\n",
    "    with np.load('{}/itemattr.npz'.format(data_dir), mmap_mode=None) as itemattr_file:\n",
    "        itemattr = {key : val for key, val in itemattr_file.items()}\n",
    "\n",
    "    return ind2val, itemattr, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind2val, itemattr, dataloaders = load_dataloaders()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('anaconda3': virtualenv)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
